{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f046155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Library to Display gifs:\n",
      "Requirement already satisfied: moviepy in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from moviepy) (1.19.2)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from moviepy) (0.4.3)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from moviepy) (2.9.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from moviepy) (2.25.1)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from moviepy) (0.1.9)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from moviepy) (4.59.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (8.2.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.4)\n",
      "Downloading pre-trained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!echo Installing Library to Display gifs:\n",
    "!pip install moviepy\n",
    "!echo Downloading pre-trained weights\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1mk9JdmJH79_vtQkl8zk-jDxa7xUXpck-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1mk9JdmJH79_vtQkl8zk-jDxa7xUXpck-\" -O state_normal81000.ckpt && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0f394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from IPython.display import Image\n",
    "\n",
    "def genSamples(g,n=8):\n",
    "    with torch.no_grad():\n",
    "        s=g(torch.rand((n**2,100),device='cuda')*2-1).cpu().detach().numpy()\n",
    "        \n",
    "    out = np.zeros((3,16,64*n,64*n))\n",
    "    \n",
    "    for j in range(n):\n",
    "        for k in range(n):\n",
    "            out[:,:,64*j:64*(j+1),64*k:64*(k+1)] = s[j*n+k,:,:,:,:]\n",
    "    \n",
    "    out = out.transpose((1,2,3,0))\n",
    "    out=(out+1)/2 *255\n",
    "    out.astype(int)\n",
    "    clip=ImageSequenceClip(list(out),fps=20)\n",
    "    clip.write_gif('sample.gif',fps=20)\n",
    "    Image(open('sample.gif', 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f3520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d22168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #generate 16 by 100 tensor, 16 represent the temporal dimension\n",
    "        self.model=nn.Sequential(\n",
    "        nn.ConvTranspose1d(100,512,kernel_size=1,stride=1,padding=0),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose1d(512,256,kernel_size=4,stride=2,padding=1),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose1d(256,128,kernel_size=4,stride=2,padding=1),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose1d(128,128,kernel_size=4,stride=2,padding=1),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(), \n",
    "        nn.ConvTranspose1d(128,100,kernel_size=4,stride=2,padding=1),\n",
    "        nn.Tanh()\n",
    "        )\n",
    "        self.model.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self,m):\n",
    "        if type(m)==nn.ConvTranspose1d:\n",
    "            nn.init.xavier_uniform_(m.weight,gain=2**0.5)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x=x.view(-1,100,1)\n",
    "        x=self.model(x).transpose(1,2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3893b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temp=TemporalGenerator()\n",
    "        \n",
    "        self.fast= nn.Sequential(\n",
    "        nn.Linear(100,256*4*4,bias=False),\n",
    "        nn.BatchNorm1d(256*4*4),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.slow =nn.Sequential(\n",
    "        nn.Linear(100,256*4*4,bias=False),\n",
    "        nn.BatchNorm1d(256*4*4),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.model=nn.Sequential(\n",
    "        nn.ConvTranspose2d(512,256,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(256,128,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(128,64,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(64,32,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(32,3,kernel_size=3,stride=1,padding=1),\n",
    "        nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.fast.apply(self.init_weights)\n",
    "        self.slow.apply(self.init_weights)\n",
    "        self.model.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self,m):\n",
    "        if type(m)==nn.ConvTranspose2d or type(m)== nn.Linear:\n",
    "            nn.init.uniform_(m.weight,a=-0.01,b=0.01)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        z_fast=self.temp(x).contiguous()\n",
    "        z_fast=z_fast.view(-1,100)\n",
    "        \n",
    "        z_fast=self.fast(z_fast).view(-1,256,4,4)\n",
    "        z_slow=self.slow(x).view(-1,256,4,4).unsqueeze(1)\n",
    "        z_slow=torch.cat([z_slow]*16,dim=1).view(-1,256,4,4)\n",
    "        \n",
    "        z=torch.cat([z_slow,z_fast],dim=1)\n",
    "        \n",
    "        out =self.model(z)\n",
    "        return out.view(-1,16,3,64,64).transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9fc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model3d=nn.Sequential(\n",
    "        nn.Conv3d(3,64,kernel_size=4,padding=1,stride=2),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv3d(64,128,kernel_size=4,padding=1,stride=2),\n",
    "        nn.BatchNorm3d(128),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv3d(128,256,kernel_size=4,padding=1,stride=2),\n",
    "        nn.BatchNorm3d(256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv3d(256,512,kernel_size=4,padding=1,stride=2),\n",
    "        nn.BatchNorm3d(512),\n",
    "        nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv2d =nn.Conv2d(512,1,kernel_size=4,stride=1,padding=0)\n",
    "        \n",
    "        self.model3d.apply(self.init_weights)\n",
    "        self.init_weights(self.conv2d)\n",
    "        \n",
    "    def init_weights(self,m):\n",
    "        if type(m)==nn.Conv3d or type(m)==nn.Conv2d:\n",
    "            nn.init.xavier_normal_(m.weight,gain=2**0.5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h=self.model3d(x)\n",
    "        h=torch.reshape(h,(-1,512,4,4))\n",
    "        h=self.conv2d(h)\n",
    "        \n",
    "        return h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22d1cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: av in c:\\users\\chand\\anaconda3\\envs\\pytorch\\lib\\site-packages (8.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f778491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import UCF101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b1004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucf_data_dir = \"P:\\\\dataset\\\\UCF-101\\\\sample\"\n",
    "ucf_label_dir = \"P:\\\\dataset\\\\UCF-101\\\\sample\"\n",
    "frames_per_clip = 16\n",
    "step_between_clips = 1\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7873d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = transforms.Compose([\n",
    "            # TODO: this should be done by a video-level transfrom when PyTorch provides transforms.ToTensor() for video\n",
    "            # scale in [0, 1] of type float\n",
    "            transforms.Lambda(lambda x: x / 255.),\n",
    "            # reshape into (C, T, H, W) \n",
    "            transforms.Lambda(lambda x: x.permute(3, 0, 1, 2)),\n",
    "            # rescale to the most common size\n",
    "            transforms.Lambda(lambda x: nn.functional.interpolate(x, (64, 64))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ca2b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    filtered_batch = []\n",
    "    for video, _, label in batch:\n",
    "        if video.shape[1]!= 16:\n",
    "            print(\"error in shape\", video.shape)\n",
    "            continue\n",
    "        filtered_batch.append((video, label))\n",
    "    return torch.utils.data.dataloader.default_collate(filtered_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5484fb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce00658158c465286b5ea9cde7400de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = UCF101(ucf_data_dir, ucf_label_dir, frames_per_clip=frames_per_clip,\n",
    "                       step_between_clips=step_between_clips, train=True, transform=tfs)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                           collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d974e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "v,l=next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47164670",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCEWithLogitsLoss()\n",
    "display_step=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfb82f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=VideoGenerator().to(device)\n",
    "gen_opt=torch.optim.Adam(gen.parameters())\n",
    "disc=VideoDiscriminator().to(device)\n",
    "disc_opt=torch.optim.Adam(disc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad94d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 500 / 0 :Generator loss: 8.696979818344117, discriminator loss: 0.09445764821554803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  18%|████████████▎                                                         | 3/17 [00:00<00:00, 17.44it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 1000 / 0 :Generator loss: 8.251449469089513, discriminator loss: 0.09155838824692553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|████████▏                                                             | 2/17 [00:00<00:00, 18.18it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 1500 / 0 :Generator loss: 8.282766531467452, discriminator loss: 0.08713800461659381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|████████▏                                                             | 2/17 [00:00<00:00, 17.09it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 2000 / 0 :Generator loss: 8.502601240992549, discriminator loss: 0.08810883671340342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|████████▏                                                             | 2/17 [00:00<00:00, 19.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 2500 / 0 :Generator loss: 8.506793653964994, discriminator loss: 0.07316077891332776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|████████▏                                                             | 2/17 [00:00<00:00, 16.02it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 3000 / 1 :Generator loss: 8.444769371271141, discriminator loss: 0.0689439903603287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|████████▏                                                             | 2/17 [00:00<00:01, 13.15it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 3500 / 1 :Generator loss: 8.727850784540177, discriminator loss: 0.08255410178151666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  18%|████████████▎                                                         | 3/17 [00:00<00:00, 17.14it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 4000 / 1 :Generator loss: 9.094063885807989, discriminator loss: 0.09024563953784395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|████████▏                                                             | 2/17 [00:00<00:00, 17.24it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 4500 / 1 :Generator loss: 9.019547147631652, discriminator loss: 0.07799030894794674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|                                                                              | 0/17 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 5000 / 1 :Generator loss: 7.700207958936685, discriminator loss: 0.056378637095482624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|████████▏                                                             | 2/17 [00:00<00:00, 16.26it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 5500 / 1 :Generator loss: 8.778859921693803, discriminator loss: 0.06628730890257929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  18%|████████████▎                                                         | 3/17 [00:00<00:00, 16.66it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 6000 / 2 :Generator loss: 9.066775604724876, discriminator loss: 0.052326812163989454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|████████▏                                                             | 2/17 [00:00<00:00, 17.56it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step / Epoch : 6500 / 2 :Generator loss: 10.116045177936549, discriminator loss: 0.06814337020918632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  12%|████████▏                                                             | 2/17 [00:00<00:00, 18.01it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file sample.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "n_epochs=5\n",
    "cur_step=0\n",
    "mean_generator_loss=0\n",
    "mean_discriminator_loss=0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i,(real,l) in enumerate(train_loader):\n",
    "        \n",
    "#         print(l)\n",
    "        real=real.to(device)\n",
    "        \n",
    "        disc_opt.zero_grad()\n",
    "        fake_noise=torch.rand((batch_size, 100), device='cuda')*2-1\n",
    "        fake=gen(fake_noise)\n",
    "#         print(fake.size)\n",
    "        disc_fake_pred=disc(fake.detach())\n",
    "        disc_fake_loss=criterion(disc_fake_pred,torch.zeros_like(disc_fake_pred))\n",
    "        disc_real_pred=disc(real)\n",
    "        disc_real_loss=criterion(disc_real_pred,torch.ones_like(disc_real_pred))\n",
    "        disc_loss =(disc_fake_loss + disc_real_loss)/2\n",
    "        \n",
    "        \n",
    "        mean_discriminator_loss+=disc_loss.item()/display_step\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        disc_opt.step()\n",
    "        \n",
    "        \n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2=torch.rand((batch_size, 100), device='cuda')*2-1\n",
    "        fake_2=gen(fake_noise_2)\n",
    "        disc_fake_pred=disc(fake_2)\n",
    "        gen_loss=criterion(disc_fake_pred,torch.ones_like(disc_fake_pred))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        \n",
    "        mean_generator_loss+=gen_loss.item()/display_step\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Step / Epoch : {cur_step} / {epoch} :Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "#             show_tensor_images(fake)\n",
    "#             show_tensor_images(real)\n",
    "            genSamples(gen)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b21e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
